[w007104@login2 ~]$ cat rim_all_in_one_sym.py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Symmetrized RIM Semantic Vector Computation

This script reads a symmetrized Pajek network file ("wiktionary_sym.net") from the working directory,
constructs the Markov transition matrix P (using uniform weighting), and computes 
    Q = P + P^2 + ... + P^niter
for each node, where niter is set to 10 (which should be >= the network diameter).
The computed semantic vectors reflect the symmetrized (undirected) connectivity of the network.
Each vector is written to "semantic_vectors_sym.txt" with 32-digit precision in scientific notation.
The computation is performed in parallel using up to 16 threads, and a progress bar is displayed.
"""

import os
import sys
import numpy as np
from scipy.sparse import csr_matrix
from tqdm import tqdm
import concurrent.futures

def parse_pajek_net(filepath, option=0, alpha=0.0):
    """
    Parse a Pajek .net file and return a normalized transition matrix P as a SciPy CSR sparse matrix.
    For option==0, each outgoing edge is given a uniform weight (1/outdegree).

    Expected .net format (for symmetrized network):
      *Vertices <num_vertices>
      <id> "<label>"
      ...
      *Arcs or *Edges
      <source> <target> <weight>
      (Any extra fields such as edge flag are ignored.)
    
    Note: The node indices in the file are assumed to be 1-indexed.
    """
    with open(filepath, 'r', encoding="utf-8") as f:
        lines = f.readlines()
    
    header = lines[0].strip().split()
    if header[0].lower() != "*vertices":
        raise ValueError("The file does not start with '*Vertices'")
    num_vertices = int(header[1])
    
    # Skip the vertex definitions.
    vertex_lines = lines[1:num_vertices+1]
    
    # Find the start of the arcs section.
    edge_start = None
    for idx, line in enumerate(lines[num_vertices+1:], start=num_vertices+1):
        if line.strip().lower().startswith("*arcs") or line.strip().lower().startswith("*edges"):
            edge_start = idx + 1
            break
    if edge_start is None:
        raise ValueError("No *Arcs or *Edges section found.")
    
    rows, cols, data = [], [], []
    for line in lines[edge_start:]:
        parts = line.strip().split()
        if len(parts) >= 3:
            src = int(parts[0]) - 1  # convert to 0-indexed
            tgt = int(parts[1]) - 1
            weight = float(parts[2])
            # Ignore self-loops.
            if src != tgt:
                rows.append(src)
                cols.append(tgt)
                data.append(weight)
    
    if option == 0:
        out_degree = [0] * num_vertices
        for r in rows:
            out_degree[r] += 1
        new_data = []
        for r, wt in zip(rows, data):
            if out_degree[r] > 0:
                new_data.append(1.0 / out_degree[r])
            else:
                new_data.append(0.0)
        P = csr_matrix((new_data, (rows, cols)), shape=(num_vertices, num_vertices))
    else:
        raise NotImplementedError("Only option 0 (uniform weighting) is implemented.")
    
    return P

def compute_semantic_vector(P, i, niter):
    """
    Compute the semantic vector for node i as:
       Q[i] = P[i] + P[i] @ P + ... + (P[i] @ P^(niter-1))
    where P[i] is the i-th row of P.
    """
    v = P.getrow(i).toarray().flatten().astype(np.float64)
    accum = v.copy()
    for iteration in range(1, niter):
        v = (v.reshape(1, -1) @ P).flatten().astype(np.float64)
        accum += v
    return accum

def rim_main():
    # Parameters defined below.
    input_filename = "wiktionary_sym.net"       # Input symmetrized network file.
    output_filename = "semantic_vectors_sym.txt"  # Output file for semantic vectors.
    niter = 10      # Number of iterations (niter must be >= network diameter; here we use 10)
    option = 0      # Uniform weighting.
    alpha = 0.0     # Not used for option 0.
    
    if not os.path.exists(input_filename):
        print(f"Input file '{input_filename}' not found!")
        sys.exit(1)
    
    print(f"Reading symmetrized network from: {input_filename}")
    P = parse_pajek_net(input_filename, option, alpha)
    num_vertices = P.shape[0]
    print(f"Parsed symmetrized network with {num_vertices} vertices.")
    
    def worker(i):
        return i, compute_semantic_vector(P, i, niter)
    
    semantic_vectors = [None] * num_vertices
    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:
        futures = {executor.submit(worker, i): i for i in range(num_vertices)}
        for future in tqdm(concurrent.futures.as_completed(futures), total=num_vertices, desc="Computing semantic vectors"):
            i, vector = future.result()
            semantic_vectors[i] = vector
    
    with open(output_filename, "w", encoding="utf-8") as f_out:
        for vector in semantic_vectors:
            row_str = " ".join(f"{val:.32e}" for val in vector)
            f_out.write(row_str + "\n")
    
    print(f"Semantic vectors (from symmetrized network) written to '{output_filename}'.")

def main():
    rim_main()

if __name__ == "__main__":
    main()
